# Qx - Finance Modeling Platform

A local-first, swappable architecture for financial modeling, built around three layersâ€”**Data**, **Model**, and **Orchestration**â€”with strict dataset typing, package-based models, and storage abstraction

## High-Level Overview

- **Data Layer:** Ingests raw sources, builds **curated** datasets (Parquet today), and loads curated data by **typed contracts**.
- **Loader Layer:** Reads curated data and transforms to lightweight outputs (lists, parameters, DataFrames) for downstream tasks. **Not persisted**.
- **Model Layer:** Each model is a **package** (`model.py` + `model.yaml`), consumes curated datasets (strict types), generates **processed** outputs with lineage.
- **Orchestration Layer:** Coordinates tasks via a **DAG** (Directed Acyclic Graph). Manages dependencies, runs, and manifestsâ€”local runner now; Azure pipelines later.

## ğŸ“ Project Structure

```plain
qx/                          # Core framework (infrastructure)
  â”œâ”€â”€ common/               # Types, contracts, predefined registry
  â”œâ”€â”€ storage/              # Backends, format adapter, path resolver
  â”œâ”€â”€ foundation/           # Base classes (base_builder, typed_loader)
  â”œâ”€â”€ engine/               # Model base, processed writer
  â”œâ”€â”€ orchestration/        # DAG, tasks, factories (run_builder, run_loader, run_model)
  â””â”€â”€ utils/                # Utilities (universe.py - loader functions)

qx_builders/                # Builder implementations (outside framework)
  â”œâ”€â”€ sp500_membership/    # builder.py + builder.yaml
  â”œâ”€â”€ tiingo_ohlcv/        # builder.py + builder.yaml
  â”œâ”€â”€ us_treasury_rate/    # builder.py + builder.yaml
  â””â”€â”€ esg_score/           # builder.py + builder.yaml

qx_loaders/                 # Loader implementations (outside framework)
  â”œâ”€â”€ historic_members     # loader.py + loader.yaml
  â”œâ”€â”€ universe_at_date     # loader.py + loader.yaml
  â”œâ”€â”€ us_treasury_rate     # loader.py + loader.yaml
  â”œâ”€â”€ ohlcv_panel          # loader.py + loader.yaml
  â”œâ”€â”€ esg_panel
  â””â”€â”€ market_proxy        

qx_models/                  # Model implementations (outside framework)
  â”œâ”€â”€ esg_factor/          # model.py + model.yaml
  â”œâ”€â”€ market_beta/         # model.py + model.yaml
  â””â”€â”€ factor_expected_returns/  # model.py + model.yaml

conf/
  â””â”€â”€ storage.yaml          # Select backend/format
```

## Layer Responsibilities

### Data Layer (Builders)

- **Builders** (`DataBuilderBase`):  
  `raw â†’ transform â†’ curated` (write Parquet under partitioned path templates).
  - Can run **standalone** (populate data lake) OR **in-pipeline** (fetch on demand)
  - Examples: SP500 Membership, Tiingo OHLCV, US Treasury Rates, ESG Scores
- **Contracts & Types**:
  - `DatasetType`: `(domain, asset_class?, subdomain, exchange?, frequency?)`
  - `DatasetContract`: `(type, schema_version, required_columns, partition_keys, path_template)`
- **Storage & Paths**:
  - `LocalParquetBackend`: local filesystem Parquet IO.
  - `TableFormatAdapter`: format-level writes (append/overwrite, future compaction).
  - `PathResolver`: renders lake-ready paths from contracts.

### Loader Layer

- **Loaders** (lightweight functions):  
  Read curated datasets by `DatasetType` + partition filters, transform to Python objects.
  - **Input**: Curated datasets (via `TypedCuratedLoader`)
  - **Output**: Lists, Dicts, DataFrames (memory only, **NOT persisted**)
  - **Usage**: Only in DAG pipelines (no standalone use)
  - **Factory**: `run_loader(load_fn, registry, backend, resolver)`
  - **Examples**:
    - `get_continuous_sp500_members()` â†’ List[symbols]
    - `filter_universe_by_market_cap()` â†’ List[symbols]
    - `load_esg_panel()` â†’ DataFrame
- **Key Principle**: Loaders bridge curated data and task parameters. They enable **data-driven pipelines** where Builder inputs come from curated data, not hardcoded values.

### Model Layer

- **BaseModel** (config-driven):  
  Loads `model.yaml`, validates **input types** and **parameters**, runs `run_impl()`, and persists **processed outputs** (Parquet) with run metadata.
- **Model package example**: `qx_models/capm/`
  - `model.yaml`: IO type constraints, parameter defaults/ranges.
  - `model.py`: `CAPMModel(BaseModel)` with feature prep and prediction logic.
- **Processed writer** (`ProcessedWriterBase`):  
  `data/processed/{output_type}/model={model}/run_date=YYYY-MM-DD/part-<run_id>.parquet`.

### Orchestration Layer

- **DAG runner (local)**:
  - `Task(id, run, deps)` executes when dependencies are satisfied.
  - `DAG(tasks).execute()` processes the graph.
- **Three factory functions**:
  - `run_builder()` â†’ Execute builder (write curated data)
  - `run_loader()` â†’ Execute loader (read curated â†’ produce parameters)
  - `run_model()` â†’ Execute model (read curated â†’ write processed)
- **Typical flow**:  
  `BuildMembership â†’ SelectUniverse (Loader) â†’ BuildOHLCV â†’ RunCAPM â†’ Portfolio`.

## Dataset Typing â€” Examples

- **Curated market data (equities OHLCV):**
  - `DatasetType`:  
    `domain=market-data, asset_class=equity, subdomain=bars, region=US|HK, frequency=daily|weekly|monthly`
  - Partitions: `(region, frequency, date, exchange)`
- **Curated risk-free (zero curve):**
  - `DatasetType`:  
    `domain=reference-rates, subdomain=yield-curves, region=US|HK, frequency=D`
  - Partitions: `(region, date, curve_id)`
- **Processed predictions (generic):**
  - `DatasetType`:  
    `domain=derived-metrics, asset_class=equity, subdomain=predictions`
